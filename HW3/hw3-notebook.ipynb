{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f2843dc",
   "metadata": {},
   "source": [
    "Anushna Prakash  \n",
    "DATA 598 - Deep Learning  \n",
    "January 28 2022  \n",
    "# <center> Homework 3 </center>  \n",
    "## Part I: The Effect of BatchNorm on a ConvNet  \n",
    "\n",
    "First, download and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94d56444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# download dataset (~117M in size)\n",
    "train_dataset = FashionMNIST('./data', train=True, download=True)\n",
    "X_train = train_dataset.data # torch tensor of type uint8\n",
    "y_train = train_dataset.targets # torch tensor of type Long\n",
    "test_dataset = FashionMNIST('./data', train=False, download=True)\n",
    "X_test = test_dataset.data\n",
    "y_test = test_dataset.targets\n",
    "\n",
    "# choose a subsample of 10% of the data:\n",
    "idxs_train = torch.from_numpy(\n",
    "    np.random.choice(X_train.shape[0], replace=False, size=X_train.shape[0]//10)).long()\n",
    "X_train, y_train = X_train[idxs_train], y_train[idxs_train]\n",
    "# idxs_test = torch.from_numpy(\n",
    "#     np.random.choice(X_test.shape[0], replace=False, size=X_test.shape[0]//10))\n",
    "# X_test, y_test = X_test[idxs_test], y_test[idxs_test]\n",
    "\n",
    "print(f'X_train.shape = {X_train.shape}')\n",
    "print(f'n_train: {X_train.shape[0]}, n_test: {X_test.shape[0]}')\n",
    "print(f'Image size: {X_train.shape[1:]}')\n",
    "\n",
    "f, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i, idx in enumerate(np.random.choice(X_train.shape[0], 5)):\n",
    "    ax[i].imshow(X_train[idx], cmap='gray', vmin=0, vmax=255)\n",
    "    ax[i].set_title(f'Label = {y_train[idx]}', fontsize=20)\n",
    "    \n",
    "# Normalize dataset: pixel values lie between 0 and 255\n",
    "# Normalize them so the pixelwise mean is zero and standard deviation is 1\n",
    "\n",
    "X_train = X_train.float()  # convert to float32\n",
    "X_train = X_train.view(-1, 784)\n",
    "mean, std = X_train.mean(axis=0), X_train.std(axis=0)\n",
    "X_train = (X_train - mean[None, :]) / (std[None, :] + 1e-6)  # avoid divide by zero\n",
    "\n",
    "X_test = X_test.float()\n",
    "X_test = X_test.view(-1, 784)\n",
    "X_test = (X_test - mean[None, :]) / (std[None, :] + 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e2349f",
   "metadata": {},
   "source": [
    "Create a Convolutional Neural Net with two convolutional layers:  \n",
    "Input $(1, 28, 28) \\rightarrow$ Convolution with $k=5$, `filters=16`, `padding=2` $\\rightarrow$ ReLU $\\rightarrow$ MaxPool with $k=2 \\rightarrow$ Convolution with $k=5$, `filters=32`, `padding=2` $\\rightarrow$ ReLU $\\rightarrow$ MaxPool with $k=2 \\rightarrow$ Linear output = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d3f8f",
   "metadata": {},
   "source": [
    "### Step 1: Figure out size `S` to flatten to  \n",
    "This is for the `torch.nn.Linear` final step.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06f18fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 228, 228])\n",
      "torch.Size([1, 16, 228, 228])\n",
      "torch.Size([1, 16, 114, 114])\n",
      "torch.Size([1, 32, 114, 114])\n",
      "torch.Size([1, 32, 114, 114])\n",
      "torch.Size([1, 32, 57, 57])\n"
     ]
    }
   ],
   "source": [
    "image_size = 228\n",
    "# 1 batch, 1 channel, 228x228 image\n",
    "dummy = torch.randn(1, 1, image_size, image_size)\n",
    "\n",
    "# Run dummy thru input layers\n",
    "conv1 = torch.nn.Conv2d(\n",
    "    in_channels=1, out_channels=16, kernel_size=5,\n",
    "    padding=2, stride=1\n",
    ")\n",
    "out = conv1(dummy)\n",
    "# 1 batch, 16 channels, image size, image size\n",
    "print(out.shape)\n",
    "relu = torch.nn.ReLU()\n",
    "out = relu(out)\n",
    "# 1 batch, 16 channels, image size, image size\n",
    "print(out.shape)\n",
    "pool = torch.nn.MaxPool2d(2)\n",
    "out = pool(out)\n",
    "# 1 batch, 16 channels, image size / kernel input size, image size / kernel input size\n",
    "print(out.shape)\n",
    "\n",
    "# Run thru second part\n",
    "# Run dummy thru input layers\n",
    "# Now has 16 input channels\n",
    "conv2 = torch.nn.Conv2d(\n",
    "    in_channels=16, out_channels=32, kernel_size=5,\n",
    "    padding=2, stride=1\n",
    ")\n",
    "out = conv2(out)\n",
    "# 1 batch, 32 channels, image size, image size\n",
    "print(out.shape)\n",
    "relu = torch.nn.ReLU()\n",
    "out = relu(out)\n",
    "# 1 batch, 32 channels, image size, image size\n",
    "print(out.shape)\n",
    "pool = torch.nn.MaxPool2d(2)\n",
    "out = pool(out)\n",
    "# 1 batch, 32 channels, image size / kernel input size, image size / kernel input size\n",
    "print(out.shape)\n",
    "\n",
    "# Now convert final out shape into 1 x 10???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "952b5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class ConvNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Defines a convolution neural net with 2 convolution layers\n",
    "    Does not employ batch norming\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv_ensemble_1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2))\n",
    "        self.conv_ensemble_2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2))\n",
    "        # Final layer output is batch x channels x imagesize / 4 x imagesize / 4\n",
    "        self.fully_connected_layer = torch.nn.Linear(7*7*32, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28) # Resize, needs channel\n",
    "        out = self.conv_ensemble_1(x) # Run thru layer 1\n",
    "        out = self.conv_ensemble_2(out) # Run thru layer 2\n",
    "        out = out.view(out.shape[0], -1)  # flatten output\n",
    "        out = self.fully_connected_layer(out)  # output layer\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89d84fe",
   "metadata": {},
   "source": [
    "Create a Convolutional Neural Net that is the same as above, but has batch norm applied after each `MaxPool2d` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03cdc763",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormConvNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Defines a convolution neural net with 2 convolution layers\n",
    "    Employ batch norming\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv_ensemble_1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.BatchNorm2d(num_features=16))\n",
    "        self.conv_ensemble_2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.BatchNorm2d(num_features=32))\n",
    "        self.fully_connected_layer = torch.nn.Linear(7*7*32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28) # Resize, needs channel\n",
    "        out = self.conv_ensemble_1(x) # Run thru layer 1\n",
    "        out = self.conv_ensemble_2(out) # Run thru layer 2\n",
    "        out = out.view(out.shape[0], -1)  # flatten output\n",
    "        out = self.fully_connected_layer(out)  # output layer\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19fb650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "model = ConvNet(num_classes=10)\n",
    "model2 = BatchNormConvNet(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfbdc10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data598]",
   "language": "python",
   "name": "conda-env-data598-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
