{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f2843dc",
   "metadata": {},
   "source": [
    "Anushna Prakash  \n",
    "DATA 598 - Deep Learning  \n",
    "January 28 2022  \n",
    "# <center> Homework 3 </center>  \n",
    "## Part I: The Effect of BatchNorm on a ConvNet  \n",
    "\n",
    "First, download and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94d56444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = torch.Size([6000, 28, 28])\n",
      "n_train: 6000, n_test: 10000\n",
      "Image size: torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABH4AAAD0CAYAAADt0eG0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA2+ElEQVR4nO3deZxddZnn8e+TpZJUtsq+ESi2BBExQASULSjKOiA9Io1Ig3YPPa30iFtD2+PItD1urSiKL3sAJTqtsZ0BA4M26CAg0oKEGCAYkRCK7JV9T2XjN3/ci12E+zxVdeoup0593q/XfVXlfOvc87vn3uecU7/cuo+llAQAAAAAAIDiGdDoAQAAAAAAAKA2mPgBAAAAAAAoKCZ+AAAAAAAACoqJHwAAAAAAgIJi4gcAAAAAAKCgmPgBAAAAAAAoKCZ+csbM5ppZMrPWGm7jpvI25tRqG0DRUJtAPlGbQD5Rm0A+UZv9ExM/GZRfxKnR4ygCM2sxs0+a2ffN7Hdmtr+8f89p9NjQ91Cb1WdmF5nZw2a21cx2mNkTZnZ1o8eFvoXarJ5yPaYubt9u9DjRN1Cb1WNms8q/7D5mZmvMbK+ZrTKzeWZ2YqPHh76F2qwuM5toZreY2YtmtsfMNpjZ/zWzUxs9tnoZ1OgBoN9rlfSl8vcrJW2QNKlhowHwR2Z2naRvSNoo6Z8l7ZX0HklzzexNKaVPNHJ8QD81V9LDTvbXksZK+td6DQbAH/2TpFMkPSXpbkk7JM2S9KeS3mNm700p/bhxwwP6JzM7TNJjkqZJ+o2k+ZLGS/oTSeeb2WX9oTaZ+EGjvSzpHEm/TSltMrO5kng3AdBg5bf/flnSJkmzU0pt5eV/L+lJSR83s7tSSr9u2CCBfiilNLfScjObKekzktol3VPPMQGQJH1f0vtTSks7LzSzK1X6z5PbzewnKaW9DRkd0H/dotKkz9clXZ9SSpJkZp9VaaL2DjN7JKW0qYFjrDn+1KvGzOzdZvbPZvYHM9tZ/lOJp8zsv5hZtP8HmNnHzOz3ZtZhZivN7KtmNsrZziFmdquZLSu/fW2jmd1rZm+p0UOripTS5pTSg0UvNOQPtdmlD0oaIunWVyd9pFLNSvpc+Z//uQHjQsFRm5ldW/56Z0ppX0NHgkKiNmMppW8cPOlTXv59SS9IGifpTXUfGAqP2vSZ2VBJF0h6RdJ/fXXSR5LK9Xq7Su+UvbIxI6wf3vFTe19Q6YX2hKRVkkZLertKM49vkXSVs95XJZ0p6Ucq/c/duZKul3SGmZ2eUup49Qet9HfDP1PpRfuASm8vHS/p3ZJ+ZWaXppR+Wu0HBvRx1Gbs7eWv91fI/vWgnwGqidrsITNrkvRnkpJKF7FALVCb2b06Gbu/oaNAUVGbvrGSBktal1LaXiFfVv76DpU+3qCwmPipvQtTSi92XlCeeb1T0p+Z2a0ppScqrHeapFkppZfL6/ytpP+t0t8iflLSZ8vLB6lUrCMknZ1SeqTTdqaq9CcZ3zaz1pTSniwPwMxmqVTUPfG1lNKWLNsD6oTajM0sf/3DwUFKaY2Z7ZR0iJk1p5R29XAMQITa7Ln/qNIF+M9TSsu6+mEgI2oz2zZPkXSsSr+QL856P0CA2vRtlnRA0ngzG5FS2nFQfkT56zE93Hbfk1Li1sObSv+jlnp5HyeW7+e/HbR8bnn5pyusc4RKL9yXOi27pPzz/+hs5yPl/IJOy24qL5vTzbFe8+pj7sGtNeN+efXxn9Po55lb37tRm9WrTZU+yDlJGuTkq8r5lEY/79zyf6M2a3feLG/vofJ9vKfRzzW3vnWjNmtem2NU+g+UJOm9jX6+ufWdG7VZ1Wvan5V//uYKj3VLOWtv9HNe6xvv+KkxMxun0ozpBSq9uIYf9CPTnFUfOXhBSmmZma2Q1GpmLak0w/nWcnyYmd1U4X6OLn99g6RMb79LpQ+SnJtlXSCvqM1es1eH0aDto6CozZ4xs6MlnSU+1Bk1Rm32jJkNl3SvSuP+UkrpR/XYLvofarNL10v6laSPmtlbJf2bSp+59SeSXpJ0vEqTXYXGxE8NmVmLSm99O1yl1nHfU6lDzn5JLSrNjg5xVm93lq+VdJhKf7u5RaUXrSRd1sVwRnRv1EDxUZvdslWlPx0ZrVI794O9+sF/2+o2IhQetZnJtSpNxN6Z+FBn1Ai12TPlSZ+fSDpdpXcZ3NDgIaGgqM2upZR+Z2YnSfq0pHdJ+mtJ6yTdIWmeSvttXeNGWB9M/NTWX6hUhP89pXRT56A82/iRYN1Jkp6vsHxy+evWg75eklK6N/tQfXzGDwqI2uza8ypN/MyQ9JqW7WY2RaX/TVqZ+HwfVBe12bPtNEm6WnyoM2qP2uz+NkaqNOlzhkrv9GHSB7VEbXZDSukllTrWHrzdD5S/fbKH2+5zmPipraPKX++qkJ3VxbpnSfpl5wVmdoSk6ZLaOr3IHy9/PUOlt5PWwixJn+nhOnNVmiEG8oja7NovVPrQv/N00MSPpPM7/QxQTdRmz1wqaYL4UGfUHrXZDWY2WqVumKdK+h8ppf/aw20BPUVt9s5flL9+v5f3k3sDGj2Agmsrf53TeaGZnSDpb7tY9yNmdlindQZI+keVnrM7O/3cPZJelPRhM7ug0h2Z2VvNrLlHI+8kpTQ3pWQ9vLVl3R5QB23lr3M6L6Q2X+NOSXskXWdmrZ3GPEbSp8r//KesYwccbeWvczovpDZd15a//s+sYwW6qa38dU7nhdTma8Y2RtL/U2nS5zNM+qBO2spf53ReSG2+ZmxDzGzIQcvMzP5e0tsk/SSl9HDWsfcVvOOnF8xsbhB/SKW/sfykpK+Z2dmSXlDpw68uknS3pMuD9R+TtMjM/kWlt9edK+nNkp6S9KVXfyiltM/M/kTSA5J+Ymb/JmmRpF0qzda+RaUP+ZpSXpY7ZvZllf6kRCr9LbQkfdLM3l/+fn5KaX7dB4Y+i9rsvZTSS2b2SUlfl7Sg/Hj3SnqPpEMkfSWldPA7gYAQtVk9ZnaUpLNV+oyGWv0PLPoJarMq7pY0W6VfkAc4H4I7P6W0qJ6DQt9GbVbF0ZIeNbOfqzRR1iTpnZKOVelPvP6scUOro5SD1mJ97abutZdrKf/ssSpdkK2TtFOlQvoLSa3ln5t70H3PLS8/QtLHJf1eUodKrZO/JmmUM6aJkr4gabFKBbdDpcL/P5Ler04tmdXD9np12J9tXezLmxo9Rm5940Zt1mSf/geVuj5sL++nJyVd3ehxcetbN2qzJvv0i+Uxfb7RY+HWd2/UZlX3ZVs39uU1jR4nt75xozarui8nqPSnXC9J2q1SY5LfqNTtq6nR46vXzco7AwAAAAAAAAXDZ/wAAAAAAAAUFBM/AAAAAAAABcXEDwAAAAAAQEEx8QMAAAAAAFBQdW3nbmZ8kvRBJk6c6GYdHR1uZmZu5n1gd/RB3tH9RdmgQf5LaOjQoW62atUqNyuylJK/MxuI2qyepqYmN9u3b1/F5Vnquatt7dmzx83wetQmkE/UZt8xevRoNxswwP+/5i1btrhZPZvQtLS0uNmBAwfcbPv27TUYTf5Rm0A+ebXZq4kfMztP0i2SBkq6I6X0hd7cX3/0vve9z82ef/55N4tOoK+88krF5d4vnZI0ePBgNxs4cKCbTZgwwc1mzpzpZjfeeKOboff6am1mnQCJ1otqJbqQy2ry5Mlutm7duorLo/rbu3evm7W2trpZdPyIRPurFrJMVPdlfbU2gaKjNntvzpw5bhb9R8X8+fPdLLp2rbZo/Fu3bnWzhx56qAaj8XnXPJw3AUQyX+Gb2UBJ35R0vqRjJV1hZsdWa2AAsqE2gXyiNoF8ojaBfKI2gerpzX/tnixpaUppWUppr6QfSrqkOsMC0AvUJpBP1CaQT9QmkE/UJlAlvZn4mSZpRad/rywvew0zu9bMFpjZgl5sC0D3UZtAPlGbQD5Rm0A+UZtAlfTmM34q/YHp6/64NKV0m6TbJD5sC6gTahPIJ2oTyCdqE8gnahOokt6842elpOmd/n2IpNW9Gw6AKqA2gXyiNoF8ojaBfKI2gSqxrJ8Ab2aDJP1B0jskrZL0pKT3pZSeC9bplzOw73rXu9zsgQceqONI8uO8885zsyLvk3q0vuzLtRl154pEnef279+fdTiuL37xi272gQ98wM3a29t7vK2RI0e62dChQ93sox/9qJvNmzevx+PoStSZzOs0KNWms1oW1CaQT9RmbUTH7NNPP93N3va2t7nZKaec4mZRy/bo3L98+fKKy5ctW+auM3Xq1EzZ+eef72b333+/m91zzz1uNmTIEDd77LHH3Gz9+vVulhfUJpBPVW/nnlLab2bXSXpApfZ634mKEEB9UJtAPlGbQD5Rm0A+UZtA9fTmM36UUvqppJ9WaSwAqoTaBPKJ2gTyidoE8onaBKqjN5/xAwAAAAAAgBxj4gcAAAAAAKCgmPgBAAAAAAAoKCZ+AAAAAAAACipzO/dMG+un7fW+9rWvudmHPvQhN3vxxRfdLGpRPWBA5fm8pqYmd51I1G550CD/88GPPPJIN/vYxz7mZl/96le7N7A+qB6tL7PIS21GLV1rcaw65phj3CyqzZNPPtnNpkyZ4maHHnpoxeVRm9uoFezixYvdrKOjw82eeOIJN7vrrrvc7PHHH3ezvo7aBPKJ2szur/7qr9zskEMOcbMdO3a4WXS+2rt3r5t516aSNHv2bDcbM2ZMxeWXXXaZu86zzz7rZvv27XOz557zm0XdfPPNbtbS0uJmb3jDG9ws2icvv/yym913331u5qnF9RW1CeSTV5u84wcAAAAAAKCgmPgBAAAAAAAoKCZ+AAAAAAAACoqJHwAAAAAAgIJi4gcAAAAAAKCgmPgBAAAAAAAoKL8XN6omah0ZtXIcPHiwmw0dOtTNBg4c2KPlUjzGaFtRW/nI8OHDM62HYsvabvTjH/+4m33wgx90s6hlbdRGffPmzW7W1tbmZq+88krF5VH9RdnOnTvdLKr3d7zjHZmyDRs2uNmiRYvc7G/+5m/cDACQ3SmnnOJmxx13nJvNnz/fzaLzX3RtOnXqVDdbsWKFm91///1uNmHChIrL9+zZ467z4osvutkTTzzhZqtXr3az6BokamO/bNkyNxs0yP81LDr3jx8/vuLy6BwNALzjBwAAAAAAoKCY+AEAAAAAACgoJn4AAAAAAAAKiokfAAAAAACAgmLiBwAAAAAAoKCY+AEAAAAAACgo2rnXwaGHHupmUTv0qHVkJGqJnRfTp09v9BCQQ167c0m68cYb3ezKK690s6i9aVR/W7dudbOo1e2IESPcbOXKlRWXb9q0yV1n8uTJbtbU1ORmBw4ccLP29nY3ix5btL0LL7ww03rXX3+9mwEAYtdcc42brV+/3s2ic0vUSnzXrl1uFp3LWlpa3Gzjxo1utnjx4orLH3nkEXed6Dp49OjRbhbtk+3bt7tZpLm5OdNYvMctSRMnTqy4nHbuACK84wcAAAAAAKCgmPgBAAAAAAAoKCZ+AAAAAAAACoqJHwAAAAAAgIJi4gcAAAAAAKCg6OpVB1GXnKiL0aBB/tMzYIA/Z+dlUZeD6P4GDhzoZllFnRPQf0Wv0WuvvdbNXnzxRTeLuuNFNTZ48GA3i+o26mridfwaOnSou87OnTvdLBJ19YqOSdGxIHrcUaewiy++2M0+//nP9/j+AAAlra2tbrZ8+XI3izrOrl692s2i83R0vho2bJibRZ2vRo0aVXG519lKis9VUXeuqPNYtN6WLVvcbObMmW4WdU+LumFmuS7P2ikYfUdUm/V8/qNr66ibbuSuu+5ys9/97ndu9ulPfzrT9vKi2s9pryZ+zKxN0nZJByTtTynN7s39AagOahPIJ2oTyCdqE8gnahOojmq84+fslNKGKtwPgOqiNoF8ojaBfKI2gXyiNoFe4jN+AAAAAAAACqq3Ez9J0s/M7Ckzq/gBHGZ2rZktMLMFvdwWgO6jNoF8ojaBfKI2gXyiNoEq6O2fep2WUlptZhMl/dzMfp9S+mXnH0gp3SbpNkkyMz5ZDKgPahPIJ2oTyCdqE8gnahOogl694yeltLr8dZ2kH0s6uRqDAtA71CaQT9QmkE/UJpBP1CZQHZnf8WNmwyUNSCltL3//Lkl/X7WRFUhHR0ejhyApbk8dtX6OsqhlZiRqGY3e6cu1+cY3vjHTetHrKWodGbVCjF73USvVqI3l3r17Ky6P2rZGoscdjSNqH79r1y43i9pKRtuLWtyfffbZFZf/8Ic/dNfpq/pybQJF1hdqc/LkyRWXR23GI0cffbSbRfc5duxYN3vyySfdbMKECW4WtYH3WqVH5+Ho3Dhy5MhM60XXu1Gr+qhle1tbm5tNmzbNzVatWuVmRdMXajMv6tmyPZK1ZftZZ53lZjNmzHCz8ePHu9ktt9ziZjfffLObrV+/3s2ia+Hdu3dXXJ719+VqP6e9+VOvSZJ+XH7wgyT9IKV0f1VGBaA3qE0gn6hNIJ+oTSCfqE2gSjJP/KSUlkl6cxXHAqAKqE0gn6hNIJ+oTSCfqE2gevh7GwAAAAAAgIJi4gcAAAAAAKCgmPgBAAAAAAAoKCZ+AAAAAAAACqo3Xb3QTVu3bnWzIUOGuFnU+i1qY+mtl7VNZdSmOatf/OIXVb9P9H3jxo1zs6i9+vDhw90sak8etUmM6iVq5Rjx6iyqv2gc0fijMT788MNuNnv2bDdrbm52s+j5GTVqlJu1tLS4GQCg5Kijjqq4PGrtvWTJEje76KKL3GzZsmVuFl0TRueyvXv3utmOHTvczDsHRue/qIX60KFD3SxqQx3d5+TJk90sOhdHbainTJniZs8991zF5dE5OroWArJoamqquDyq9WnTprnZrbfe6mbRfUbHgtNOO83NrrrqKjfbuXOnm0XHOa+d++bNm911tm/f7mbRPrn33nvdzMM7fgAAAAAAAAqKiR8AAAAAAICCYuIHAAAAAACgoJj4AQAAAAAAKCgmfgAAAAAAAAqKiR8AAAAAAICCop17HbS3t7tZ1lbNUea12hwxYoS7TtTmMWpFGbW+jESPG/3X4Ycf7mbRa23w4MFuFrV6z9JCVsreRj3LtrK2jo/2yYQJE9ws2s9Ry3avracUt76MWgMD1ZSlpqNaz5Osx4ksjy86tkQtr9E7Xuvv6Ji9cOFCN4ueq7e85S1u9vDDD7vZuHHj3CxrO+YsBg4c6GZZzzlZW70/8sgjbnbllVe62UsvvdS9gXUycuRIN6OdO7KIzpteTUfr3HHHHW4WnVseffRRN4uOOy0tLW4WjXPo0KFuFh0LvPWi2pw4caKbLV261M1o5w4AAAAAAIA/YuIHAAAAAACgoJj4AQAAAAAAKCgmfgAAAAAAAAqKiR8AAAAAAICCYuIHAAAAAACgoOijWwc7d+7MtF7UOjlqeee1bY9a4c2aNcvN9uzZ42ZZW8hGrZ/Rf3mvXSl7m/ExY8a4WVSbUTvYqD15xGsdWe328FK8v0488UQ327Ztm5sNHz480/ai/Rw950BPRXUbHSeyuOSSS9xs3rx5bnbDDTe42Te+8Q03q0Ub9aidrXeci7bltRyX4v2/efNmN0OJ1w64o6PDXWfq1KluFrVlP//8893sqKOOcrP29nY3i84t0TnVy6J6yNrOPWp5Hm0veg6ic+Pxxx/vZr/5zW/czHsMw4YNc9cBPFnOA5HPfvazbtbc3OxmmzZtcrOTTjrJzby28lL8+2Z0nIiOBdH+8s5z0Rij81/Uqj4L3vEDAAAAAABQUEz8AAAAAAAAFBQTPwAAAAAAAAXFxA8AAAAAAEBBMfEDAAAAAABQUEz8AAAAAAAAFFSX7dzN7DuSLpK0LqV0XHnZWEn/IqlVUpuk96aU6MXpWL16dab1otaREa/l5ze/+U13nblz57pZ1Ioyak8XWbt2bab18O+KWJsTJ050sx07drhZ1Foxaj0cvbajtqjRfWZpfZm1ZXvUBj5qUxm11Y325fLly91s0qRJmcZyxBFHuFlfVcTa7Cuytmx///vfX3H5hz/8YXed6HW9bt06N7vgggvcLGrnnrVleyTL8WrOnDluFrWxf/zxx93s0ksv7fE4sujLtTl58uSKy6NrzOnTp7vZs88+62bR6+Kcc85xs4ULF7rZ+vXr3Sw6l3lZVH/ReWzIkCFutnv3bjeLtrd161Y3GzNmTKb7PPTQQ91s5cqVFZePGjXKXSfv+nJt9letra0Vl19xxRXuOtG1fHT8mDFjhptFNR21Sj/kkEPcbOzYsW6W5TojOrZEv+/Pnj27x9uKdOcdP3MlnXfQshslPZhSOlrSg+V/A6ivuaI2gTyaK2oTyKO5ojaBPJorahOoqS4nflJKv5S06aDFl0j6bvn770p6d3WHBaAr1CaQT9QmkE/UJpBP1CZQe1k/42dSSmmNJJW/+n+fAaCeqE0gn6hNIJ+oTSCfqE2girr8jJ/eMrNrJV1b6+0A6BlqE8gnahPIJ2oTyCdqE+ha1nf8tJvZFEkqf3U/xTCldFtKaXZKqbqfTgSgEmoTyCdqE8gnahPIJ2oTqKKsEz/3Srq6/P3Vku6pznAA9BK1CeQTtQnkE7UJ5BO1CVRRd9q5z5M0R9J4M1sp6TOSviDpR2b255KWS7qsloPs65YtW5ZpvajN4/Dhw3t8fz/+8Y/d7Pbbb3ez5uZmN9uzZ0+PxyFJbW1tmdbDvytibZ522mluNmLECDdraWlxs8cee8zNohaQo0ePdrOo/XrUltZrkRu1no1kbec+aJB/6N+5c6eb7dq1y81mzpzpZi+88IKbRc9rX1XE2sz6mq+3a665xs0uu8zf5WeccUbF5VGb5g0bNrjZpk0Hf0bpvzvrrLPc7MUXX3SzK6+80s2iVumRqVOnutm3vvWtisvPPPNMd52mpiY3mzZtWvcHViN9uTa91skPPPBApvuLWrY/9dRTbubViiTt27fPzfbv3+9m0TnQO/ZE9xe9DqP1so4/El3vRi2evedbkh566KGKy6Nrobzry7XZF0TXfdFr+7DDDnOzu+++u+Ly6JovujY9/vjj3Sxqeb59+3Y3ix7br3/9azeLrk2j49WwYcMqLo+OLdH1VdTGPosuJ35SSlc40TuqOhIAPUJtAvlEbQL5RG0C+URtArWX9U+9AAAAAAAAkHNM/AAAAAAAABQUEz8AAAAAAAAFxcQPAAAAAABAQTHxAwAAAAAAUFBddvVC70Vt7SIHDhxws1GjRrlZR0dHj7e1efNmN4ta+UUt6CLt7e2Z1kOxXXXVVW527rnnutnhhx/uZlG7xn/4h39wsyx1lFXUDjtrjUWtI6M29mPHjnWz6Pn53Oc+52bR8WXFihVuhpKsrwFP1E7V21b0esrq7LPPdrPLL7/czaJ6P/nkk90seh2uXr264nKvNaskTZkyxc327t3rZi+//LKbjR8/3s0efPBBN8t6vBo5cqSbee2+169f764TtbmN2tIed9xxFZcvXbrUXaeIsrQJ3rRpk7vO0Ucf7WZRy/bm5mY3Gzp0qJutWrUq03rRMc67Fo7a0UeiY1nWdu6TJk1ys6efftrNtm3b5mYTJ050M0+1zxXoniz7Pbrui0RtzbO+fiOf+MQn3Gznzp0Vl7e0tLjrvPTSS262e/duN2ttbXWz6PflMWPGuFlkz549bhYdp73W8tHx79FHH+3+wDrxrhe2bNnirsM7fgAAAAAAAAqKiR8AAAAAAICCYuIHAAAAAACgoJj4AQAAAAAAKCgmfgAAAAAAAAqKiR8AAAAAAICCop17HUQtZCNRe8CodeuGDRt6vK0dO3a4mdeuT8rejjBqP4r+y2upLEl33nln1bf39a9/3c2ytnyN2jxmqZfoOBC15Y7G2NTU5GYjRoxws6hVb5Shd7IeZz1Z27p6Lr74Yje7+uqr3eykk05yM68lqhTX2PLly91s7Nixbua1yo72VVRjUW0OHz7czaJzcdT6OTpORK11o+sT7z6zthMePXq0mx1xxBEVl69YscJdp4iilr/ea2PIkCHuOlEdZW1XfNRRR2XaXrRe9Dr0ainruTZq/RzVUdRqOqr3yC9+8Qs3O+ecc9xs8uTJFZdH5/bosVX7HJNn0X6IXlNZ1ov2a/SaiX7Hi46xkVNOOcXNPvCBD7jZhRde6GYvvPBCxeVr165115k2bZqbRb8DROe/kSNHull0nItEx4nousCrweh5O/bYY90sOm5Gr0kP7/gBAAAAAAAoKCZ+AAAAAAAACoqJHwAAAAAAgIJi4gcAAAAAAKCgmPgBAAAAAAAoKLp61UH0yeCR6NO6Bw3yn7rFixf3eFvRJ5TXohPA1q1bM62HYsv6ms/a5SBrl46opqOuGt56USeJrLLWbdYOCJFoX77yyisVl/enLiO1cNhhh7nZiSee6GazZs2quPzss89214k6kERditrb292subnZzaIuRuPHj3ezaJzeOTCqh+h1nbX+ov3l1UpXWXScix6fd1z1OqBJ8eOOzvtTpkypuDzqIFZEEydOdDPvuYq6xEWd1KLXRVRjS5YscbMxY8a4WXQOj2pz1KhRbubJ2tUrqqPo3J5V1MVo165dbuZ1xj3yyCPddaLnNNr/fZV3LMr62qi2rNetUY196EMfcrPLL7/czaJufPPnz3ezSZMmVVwe7eO9e/e6WdTdKuowHWVRTUc1kbXDm/caijqPRfsry+9FYQc6NwEAAAAAAECfxsQPAAAAAABAQTHxAwAAAAAAUFBM/AAAAAAAABQUEz8AAAAAAAAFxcQPAAAAAABAQdHOvQ6iVnKRqB1b1EZ26dKlPd7Whg0b3GzmzJluFo0xUsTWkei9erfZjNoSR61U6ylqgeu1oJbiVpTRfq7F446OgbRtjw0ZMkStra0Vs9tvv91dz2vLLsXtVL3nf8uWLe46XmthKW5hGp3HIlEL8ug4EbWs9eosqqNIVLeRqP6ixxbt50jULt07PmZtOT9ixIhM6/UnkydPdrOtW7dWXP7MM8+461x00UVuFl33eduSpJUrV7rZuHHjMt1n9Nrw2qhH9RCdG6NzTrReVtFx7vnnn3ezQw891M0uvPDCissXLVrkrpO1fXhfleXaYvjw4W4WHaO89Y455hh3nTe96U1udsIJJ7jZ8ccf72YbN250s3vuucfNjjrqKDeLjkleFp1XIrt373azaP9H5+moZfuOHTvcbNu2bW7mtbGXpFGjRlVcHl1DRb9LR5n3uouuybq8ojGz75jZOjNb3GnZTWa2yswWlW8XdHU/AKqL2gTyidoE8onaBPKJ2gRqrzv/lTVX0nkVln81pTSrfPtpdYcFoBvmitoE8miuqE0gj+aK2gTyaK6oTaCmupz4SSn9UpL/niEADUFtAvlEbQL5RG0C+URtArXXmw93vs7Mnim/NW+M90Nmdq2ZLTCzBb3YFoDuozaBfOpxbdbis60AvA7nTSCfqE2gSrJO/HxL0pGSZklaI+kr3g+mlG5LKc1OKc3OuC0A3UdtAvmUqTazfgAygG7jvAnkE7UJVFGmiZ+UUntK6UBK6RVJt0s6ubrDApAFtQnkE7UJ5BO1CeQTtQlUV6Z+o2Y2JaW0pvzPSyUtjn4e2UTt6aK3/0ftIT1PP/20m51++ululrWdOy2ca4Pa7Jmo5XLU8jrruzC8eonaVNa7xrJuL+t99pdjQdba3LNnj3tM/+IXv+iud9xxx7lZ1GJ29OjRFZc3Nze765x66qlulrX1d9TW1WszLmV//XrtZ6P7y1q3WV/z0TEp2l7Uxrm9vd3NvONc1AY8GqP32pKkxx57rOLyqN1uteTpvBmdk7zXvdc+WJLWrl3rZrt27XKzqIVz1Mo4qs2onXHUzt27z6jdctSWPTp/R/s/Wi86XkXHwGif7Nmzx81GjhzpZp7oseX1T4qz1uaAAQPcVte33nqru160X3fu3OlmU6ZMqbg8qofoNRod96Lf8aJzy5vf/GY3i84f0evXO282NTX1eB0pPldFotd2tL3oOY3OV1G9e+fA6HgbtZyv9u8iXU78mNk8SXMkjTezlZI+I2mOmc2SlCS1SfrLHm8ZQK9Qm0A+UZtAPlGbQD5Rm0DtdTnxk1K6osLib9dgLAB6gNoE8onaBPKJ2gTyidoEaq83Xb0AAAAAAACQY0z8AAAAAAAAFBQTPwAAAAAAAAXFxA8AAAAAAEBBZWrnjuqJ2sFG7dyjNoBLly7t8TjWrFnT9Q9V0F9aMaOYsrYwjWozus9oPU/WGou2FR13ohaWWdWiRXx/4rUq/clPfuKuE2V5kaUepLg9a5RFrU+9OovqOaqjqG6jlrV5bauM+hg3bpybea+NqHVy1vbIxxxzjJtFrdej9uTRaztqe+3JWkdZr62zHluixxa1k47W89pJb9++3V0nassdtY7vi6ZMmaLrrruuYjZt2jR3vRUrVrhZ9ByvW7eu4vKoNrO04pakGTNmZLrP6JwUXaNF63m1FLUgz3pMiu4zev1mPadG+zJqH+/tk6hle3Qt0d7e7mZjxoypuHzlypXuOrzjBwAAAAAAoKCY+AEAAAAAACgoJn4AAAAAAAAKiokfAAAAAACAgmLiBwAAAAAAoKCY+AEAAAAAACgo2rk32K5du9wsa6vbqPWbJ2phmbXlIJAHUZvKqOVhJGtNeGPJ2rI9y7ak+NiyatWqTOtF7SiRnZm5bYTHjh3rrhe1kc3SFjU6V2Vtz5r1NRO1bu0LbYmj2oyOLVmzqPVsFlFb2ugYEbWTXr16dcXl0bVJER122GFu5rXwjvZRVOuRt7/97W7mPVeStGPHDjeLWtW3tLS4mdciPus5LlovqpVoP0fHwObmZjeLeI9b8h9fNI6oHX3R7N+/X5s3b66YRc//7Nmz3Wzbtm1u5r3us7RCl+Lzd0dHh5tlaTMuxeePaH955/BoHKNHj3az6BwRic5JWc+bURv4aJ94z3l0LI6uu4899lg3y4J3/AAAAAAAABQUEz8AAAAAAAAFxcQPAAAAAABAQTHxAwAAAAAAUFBM/AAAAAAAABQUEz8AAAAAAAAFRTv3BovaxUXt8KJWclns3LnTzbK2IwSqKWsr8alTp7pZ1DrSa53blSyt3qMay9qyNhK1pY1avkbtwzds2JBpLIillNzXYvQazdrC1Gs9PGrUKHed6DWTtU1sJKqXrLLUUnTcibIsxwgpfty1yLI8P9VusV3ta528mz59uptlOcZGrZ8jb33rW91syZIlme4zarkctTrO0io7qr+sstZtLa6Tvd8dot8p+pMhQ4aotbW1YrZw4UJ3vej3rhkzZriZd50ZXWNmvQ6LjolRNnHiRDeLXtvRPvHqbNeuXe460XXLtm3b3GzTpk1utnHjxkzbW7duXabtecckSdq3b1+PlkvxGMeNG+dm48ePr7g8es74rR0AAAAAAKCgmPgBAAAAAAAoKCZ+AAAAAAAACoqJHwAAAAAAgIJi4gcAAAAAAKCgmPgBAAAAAAAoqC7buZvZdEnfkzRZ0iuSbksp3WJmYyX9i6RWSW2S3ptS2ly7ofY/UXu9qFXl2rVre7yt7du3Z9oW7dwbp7/VZtbX2uzZs92sFq2Cs7RHztqeM9onURa1zh02bJibee1RpbjVcH9ryZyH2oza+kZZ9NoA+ro81GYkasObZZ3Nm7M9hMmTJ7vZ008/7WaTJk1ys6i1dcS7Fo6uTbO2c4/Wi46bURvqaF+2tbW5WdRq2mvxHLWFbmpqcrM8qGZtrlmzRp/73OcqZvPmzXPXi1puP/roo262cuXKisujfe61gJfiFt7Nzc1uFr1+o3N7R0eHm0X7ZOvWrRWXR/UQtULfsmWLm0W/p0bXmNHv0oMHD86URbxr7+g4HY0/etxjx47t8ba685vUfkkfTym9QdKpkj5sZsdKulHSgymloyU9WP43gPqhNoF8ojaBfKI2gXyiNoEa63LiJ6W0JqW0sPz9dklLJE2TdImk75Z/7LuS3l2jMQKogNoE8onaBPKJ2gTyidoEaq9H7yk1s1ZJJ0h6QtKklNIaqVSsZjbRWedaSdf2cpwAAtQmkE/UJpBP1CaQT72tzejPe4D+rNsfmmFmIyTdJen6lJL/x3sHSSndllKanVLyP2gDQGbUJpBP1CaQT9QmkE/VqE0+fxSorFuVYWaDVSrC76eU7i4vbjezKeV8iiT/U8gA1AS1CeQTtQnkE7UJ5BO1CdRWlxM/Vvqo6W9LWpJSurlTdK+kq8vfXy3pnuoPD4CH2gTyidoE8onaBPKJ2gRqrzuf8XOapKskPWtmi8rLPiXpC5J+ZGZ/Lmm5pMtqMsKCe+GFF9zsiCOOcLM9e/a4WdRW2bNr164eryPxd7QNRm12w8yZM90saqGYtR1sdJ9eq/es7c5r0SY9agM5a9YsN1uwYIGbRW1wC4raBPIp17UZte71rvui67CXX3450ziiVsbRdeuQIUPcLOs51RM97uicE/0ZUHSfURa1Ub/hhhvc7PHHH3ez3/72t2525plnVlw+YsQId52oxXZOVK029+3b57ZYP+OMM9z1Tj/9dDc799xz3WzOnDkVl2dtXb5w4UI3W79+vZtt3ux3uR86dKibRXUb8dqJt7S0uOtMnz7dzWbMmJFpHNF1a9TG3rsm7+o+o9+ZvfuMthVl06ZNc7NFixZVXB4d47qc+Ekp/UqS99vFO7paH0BtUJtAPlGbQD5Rm0A+UZtA7fHpVwAAAAAAAAXFxA8AAAAAAEBBMfEDAAAAAABQUEz8AAAAAAAAFBQTPwAAAAAAAAXVnXbuqKF9+/a5WVNTk5u1t7dXdRxR68us7e6ixwb0VNSSMeK1m5Syt5eNXvfRfXp1Vu02t725z/3797vZG9/4xkz3GR1DAAAlWdq5jxo1yl0nav18/vnnu1nUnnzdunVuNnnyZDeLzknROcKscqOnaJ2oHX20XnTdGp33R44c6WZ33HGHm0WiNs7e9dCmTZvcdaLntIi8ltbR6/BXv/pVpszT2trqZqeeeqqbDRs2zM2OOeYYN2tubnYz7/ghxceJiRMnuplXE7///e/ddaL979W6FP/ee8IJJ7hZVBMDBw50s/Hjx7vZ2rVr3Wz48OEVl0e/wyxfvtzNlixZ4mb33XdfxeUdHR3uOrzjBwAAAAAAoKCY+AEAAAAAACgoJn4AAAAAAAAKiokfAAAAAACAgmLiBwAAAAAAoKCY+AEAAAAAACgo2rk32JgxY9wsasuXtbW1J2p3F4la4e3YsSPrcICq8VorSnHr1qitZCSqCa+NZbStrOPIymuBKsXtLQEAvTNp0iQ3GzJkSMXlUWvhrNt6/PHHM91ndP6LHDhwINN6nqamJjeLzvsRb/9L0oYNG9ws2s+R6Nzv/e4QPe5Ro0a5WRGv16O24fXS1taWKUPPzJs3r9FD6DN4xw8AAAAAAEBBMfEDAAAAAABQUEz8AAAAAAAAFBQTPwAAAAAAAAXFxA8AAAAAAEBB0dWrwaJOAEcffbSbDR48uKrj2L17t5tF3RYGDfJfQhs3buzVmIBqaGlpcbOUkptF3a2iLLrPLLJ29cq6XtQJY9iwYZnuEwDQtREjRrhZe3t7xeVZO2JFXYUuv/xyN4uu7aLxR6JOW3v27Onx/UXdxTo6OjKNI8qijllZRb8feJ19p0+f7q4TXROsXr26+wMD0Gfxjh8AAAAAAICCYuIHAAAAAACgoJj4AQAAAAAAKCgmfgAAAAAAAAqKiR8AAAAAAICCYuIHAAAAAACgoLps525m0yV9T9JkSa9Iui2ldIuZ3STpP0laX/7RT6WUflqrgRbV+vXr3SxqvVjtdu5Rm+ampiY3oz1k4xSxNqPXU9Y26VGtRK3Lo7Hs2LEj03pei9ms7Xgjgwb5h/doX0atc6NjQVbe/sr6fOdBEWsTKIK81+bPf/5zN5sxY0bF5dF5LPLwww+72Tvf+U43O+mkk9wsOjdG56SdO3e6mSfrOSJq9T5y5Eg3279/v5sNGOD/P/qmTZu6N7CDzJ8/381aWloqLl++fLm7jtcCPi/yXptAEXQ58SNpv6SPp5QWmtlISU+Z2atnpq+mlL5cu+EBCFCbQD5Rm0A+UZtAPlGbQI11OfGTUlojaU35++1mtkTStFoPDECM2gTyidoE8onaBPKJ2gRqr0ef8WNmrZJOkPREedF1ZvaMmX3HzMZUe3AAuofaBPKJ2gTyidoE8onaBGqj2xM/ZjZC0l2Srk8pbZP0LUlHSpql0gztV5z1rjWzBWa2oPfDBXAwahPIJ2oTyCdqE8gnahOonW5N/JjZYJWK8PsppbslKaXUnlI6kFJ6RdLtkk6utG5K6baU0uyU0uxqDRpACbUJ5BO1CeQTtQnkE7UJ1FaXEz9WarnybUlLUko3d1o+pdOPXSppcfWHB8BDbQL5RG0C+URtAvlEbQK1152uXqdJukrSs2a2qLzsU5KuMLNZkpKkNkl/WYPxFd7u3bvdLGrRGbWOzGL48OFuFrWnjtpQP/fcc70aE7pEbXbDtGn+ZwMOHTrUzaJWsSNGjHCzatdmJBpjVLdR69yoZfuuXbu6N7Ae6Mtt2wPUJpBPua7NKVOmuNmhhx5acfkf/vCHqo/j7/7u79xs0qRJbnbIIYe42cSJE92subnZzbxzanSNHJ3HBg8e7GYdHR1uFp03V6xY4WarV692s8iYMf5H2Rx55JE9Wi5Jzz77bKZx1FGuaxMogu509fqVpEq/Qfy0+sMB0F3UJpBP1CaQT9QmkE/UJlB79fuvaQAAAAAAANQVEz8AAAAAAAAFxcQPAAAAAABAQTHxAwAAAAAAUFBM/AAAAAAAABRUd9q5o4YWL17sZhdffLGbrV+/vqrjiO5vzZo1bjZu3Dg3W7BgQa/GBFTDD37wAzeL2stu2LAh0/aiFrN79+6tuHzgwIHuOlGb2wkTJrjZvn373Gzjxo1uNnbsWDfbtm2bmwEAeue+++5zsyeffLLi8pdffrlWw6movb09U4aeiVrE33HHHRWXp5TcdbZv397rMQHo23jHDwAAAAAAQEEx8QMAAAAAAFBQTPwAAAAAAAAUFBM/AAAAAAAABcXEDwAAAAAAQEEx8QMAAAAAAFBQFrX+q/rGzNZLerXv5HhJ2folV19exsI4Xi8vY6nGOA5LKfn9txuI2uwS43i9vIyF2myMvIyFcbxeXsZCbdZfXsYh5WcseRmHlJ+xUJv1l5dxSPkZC+N4vZrWZl0nfl6zYbMFKaXZDdn4QfIyFsbxenkZS17GUQ95eqx5GQvjeL28jCUv46iHPD3WvIyFcbxeXsaSl3HUQ14ea17GIeVnLHkZh5SfseRlHPWQl8eal3FI+RkL43i9Wo+FP/UCAAAAAAAoKCZ+AAAAAAAACqqREz+3NXDbB8vLWBjH6+VlLHkZRz3k6bHmZSyM4/XyMpa8jKMe8vRY8zIWxvF6eRlLXsZRD3l5rHkZh5SfseRlHFJ+xpKXcdRDXh5rXsYh5WcsjOP1ajqWhn3GDwAAAAAAAGqLP/UCAAAAAAAoKCZ+AAAAAAAACqohEz9mdp6ZPW9mS83sxkaMoTyONjN71swWmdmCOm/7O2a2zswWd1o21sx+bmYvlL+OadA4bjKzVeX9ssjMLqjDOKab2UNmtsTMnjOzj5SXN2KfeGOp+36pN2qT2qwwjlzUZn+uS4naLG+b2nztOKjNHKA2qc0K46A2GywvdVkeS0NqMy91GYyF2qxzbdb9M37MbKCkP0h6p6SVkp6UdEVK6Xd1HUhpLG2SZqeUNjRg22dK2iHpeyml48rLviRpU0rpC+WD1JiU0g0NGMdNknaklL5cy20fNI4pkqaklBaa2UhJT0l6t6RrVP994o3lvarzfqknavOP26Y2XzuOXNRmf61LidrstG1q87XjoDYbjNr847apzdeOg9psoDzVZXk8bWpAbealLoOx3CRqs6612Yh3/JwsaWlKaVlKaa+kH0q6pAHjaKiU0i8lbTpo8SWSvlv+/rsqvQAaMY66SymtSSktLH+/XdISSdPUmH3ijaXoqE1RmxXGkYva7Md1KVGbkqjNCuOgNhuP2hS1WWEc1GZjUZfKT10GY6m7/l6bjZj4mSZpRad/r1TjDkJJ0s/M7Ckzu7ZBY+hsUkppjVR6QUia2MCxXGdmz5TfmleXtwG+ysxaJZ0g6Qk1eJ8cNBapgfulDqhNH7Wp/NRmP6tLidqMUJuiNhuI2vRRm6I2GyRPdSnlqzbzVJcStVnX2mzExI9VWNaonvKnpZROlHS+pA+X34YG6VuSjpQ0S9IaSV+p14bNbISkuyRdn1LaVq/tdnMsDdsvdUJt5l+/r81+WJcStdkXUJvU5quozXyhNvtfbeapLiVq00Nt1rk2GzHxs1LS9E7/PkTS6gaMQyml1eWv6yT9WKW3BjZSe/lv/l792791jRhESqk9pXQgpfSKpNtVp/1iZoNVevF/P6V0d3lxQ/ZJpbE0ar/UEbXpozZzUJv9tC4lajNCbVKbjURt+qhNarNRclOXUu5qMxd1KVGbjajNRkz8PCnpaDM73MyaJP2ppHvrPQgzG17+MCWZ2XBJ75K0OF6r5u6VdHX5+6sl3dOIQbz6wi+7VHXYL2Zmkr4taUlK6eZOUd33iTeWRuyXOqM2fdRmg2uzH9elRG1GqE1qs5GoTR+1SW02Si7qUsplbeaiLiVqs9I4ar5PUkp1v0m6QKVPW39R0t81aAxHSHq6fHuu3uOQNE+lt3DtU2lm+s8ljZP0oKQXyl/HNmgc/0vSs5KeUakQptRhHKer9DbMZyQtKt8uaNA+8cZS9/1S7xu1SW1WGEcuarM/12X58VOb1ObB46A2c3CjNqnNCuOgNht8y0NdlsfRsNrMS10GY6E261ybdW/nDgAAAAAAgPpoxJ96AQAAAAAAoA6Y+AEAAAAAACgoJn4AAAAAAAAKiokfAAAAAACAgmLiBwAAAAAAoKCY+AEAAAAAACgoJn4AAAAAAAAK6v8DyQ5qWhCGE/4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# download dataset (~117M in size)\n",
    "train_dataset = FashionMNIST('./data', train=True, download=True)\n",
    "X_train = train_dataset.data # torch tensor of type uint8\n",
    "y_train = train_dataset.targets # torch tensor of type Long\n",
    "test_dataset = FashionMNIST('./data', train=False, download=True)\n",
    "X_test = test_dataset.data\n",
    "y_test = test_dataset.targets\n",
    "\n",
    "# choose a subsample of 10% of the data:\n",
    "idxs_train = torch.from_numpy(\n",
    "    np.random.choice(X_train.shape[0], replace=False, size=X_train.shape[0]//10)).long()\n",
    "X_train, y_train = X_train[idxs_train], y_train[idxs_train]\n",
    "# idxs_test = torch.from_numpy(\n",
    "#     np.random.choice(X_test.shape[0], replace=False, size=X_test.shape[0]//10))\n",
    "# X_test, y_test = X_test[idxs_test], y_test[idxs_test]\n",
    "\n",
    "print(f'X_train.shape = {X_train.shape}')\n",
    "print(f'n_train: {X_train.shape[0]}, n_test: {X_test.shape[0]}')\n",
    "print(f'Image size: {X_train.shape[1:]}')\n",
    "\n",
    "f, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i, idx in enumerate(np.random.choice(X_train.shape[0], 5)):\n",
    "    ax[i].imshow(X_train[idx], cmap='gray', vmin=0, vmax=255)\n",
    "    ax[i].set_title(f'Label = {y_train[idx]}', fontsize=20)\n",
    "    \n",
    "# Normalize dataset: pixel values lie between 0 and 255\n",
    "# Normalize them so the pixelwise mean is zero and standard deviation is 1\n",
    "\n",
    "X_train = X_train.float()  # convert to float32\n",
    "X_train = X_train.view(-1, 784)\n",
    "mean, std = X_train.mean(axis=0), X_train.std(axis=0)\n",
    "X_train = (X_train - mean[None, :]) / (std[None, :] + 1e-6)  # avoid divide by zero\n",
    "\n",
    "X_test = X_test.float()\n",
    "X_test = X_test.view(-1, 784)\n",
    "X_test = (X_test - mean[None, :]) / (std[None, :] + 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f3d995",
   "metadata": {},
   "source": [
    "Create a Convolutional Neural Net with two convolutional layers:  \n",
    "Input $(1, 28, 28) \\rightarrow$ Convolution with $k=5$, `filters=16`, `padding=2` $\\rightarrow$ ReLU $\\rightarrow$ MaxPool with $k=2 \\rightarrow$ Convolution with $k=5$, `filters=32`, `padding=2` $\\rightarrow$ ReLU $\\rightarrow$ MaxPool with $k=2 \\rightarrow$ Linear output = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f3ffc1",
   "metadata": {},
   "source": [
    "### Step 1: Figure out size `S` to flatten to  \n",
    "This is for the `torch.nn.Linear` final step.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db2169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 28, 28])\n",
      "torch.Size([1, 16, 28, 28])\n",
      "torch.Size([1, 16, 14, 14])\n",
      "torch.Size([1, 32, 14, 14])\n",
      "torch.Size([1, 32, 14, 14])\n",
      "torch.Size([1, 32, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "# 1 batch, 1 channel, 228x228 image\n",
    "dummy = torch.randn(1, 1, image_size, image_size)\n",
    "\n",
    "# Run dummy thru input layers\n",
    "conv1 = torch.nn.Conv2d(\n",
    "    in_channels=1, out_channels=16, kernel_size=5,\n",
    "    padding=2, stride=1\n",
    ")\n",
    "out = conv1(dummy)\n",
    "# 1 batch, 16 channels, image size, image size\n",
    "print(out.shape)\n",
    "relu = torch.nn.ReLU()\n",
    "out = relu(out)\n",
    "# 1 batch, 16 channels, image size, image size\n",
    "print(out.shape)\n",
    "pool = torch.nn.MaxPool2d(2)\n",
    "out = pool(out)\n",
    "# 1 batch, 16 channels, image size / kernel input size, image size / kernel input size\n",
    "print(out.shape)\n",
    "\n",
    "# Run thru second part\n",
    "# Run dummy thru input layers\n",
    "# Now has 16 input channels\n",
    "conv2 = torch.nn.Conv2d(\n",
    "    in_channels=16, out_channels=32, kernel_size=5,\n",
    "    padding=2, stride=1\n",
    ")\n",
    "out = conv2(out)\n",
    "# 1 batch, 32 channels, image size, image size\n",
    "print(out.shape)\n",
    "relu = torch.nn.ReLU()\n",
    "out = relu(out)\n",
    "# 1 batch, 32 channels, image size, image size\n",
    "print(out.shape)\n",
    "pool = torch.nn.MaxPool2d(2)\n",
    "out = pool(out)\n",
    "# 1 batch, 32 channels, image size / kernel input size, image size / kernel input size\n",
    "print(out.shape)\n",
    "\n",
    "# Now convert final out shape into 1 x 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d1984b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Defines a convolution neural net with 2 convolution layers\n",
    "    Does not employ batch norming\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv_ensemble_1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2))\n",
    "        self.conv_ensemble_2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2))\n",
    "        # Final layer output is batch x channels x imagesize / 4 x imagesize / 4\n",
    "        self.fully_connected_layer = torch.nn.Linear(7*7*32, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28) # Resize, needs channel\n",
    "        out = self.conv_ensemble_1(x) # Run thru layer 1\n",
    "        out = self.conv_ensemble_2(out) # Run thru layer 2\n",
    "        out = out.view(out.shape[0], -1)  # flatten output\n",
    "        out = self.fully_connected_layer(out)  # output layer\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b8d9dd",
   "metadata": {},
   "source": [
    "Create a Convolutional Neural Net that is the same as above, but has batch norm applied after each `MaxPool2d` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ebdc460",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormConvNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Defines a convolution neural net with 2 convolution layers\n",
    "    Employ batch norming\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv_ensemble_1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.BatchNorm2d(num_features=16))\n",
    "        self.conv_ensemble_2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.BatchNorm2d(num_features=32))\n",
    "        self.fully_connected_layer = torch.nn.Linear(7*7*32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28) # Resize, needs channel\n",
    "        out = self.conv_ensemble_1(x) # Run thru layer 1\n",
    "        out = self.conv_ensemble_2(out) # Run thru layer 2\n",
    "        out = out.view(out.shape[0], -1)  # flatten output\n",
    "        out = self.fully_connected_layer(out)  # output layer\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8e85605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "model = ConvNet(num_classes=10)\n",
    "model2 = BatchNormConvNet(num_classes=10)\n",
    "\n",
    "out = model(dummy)\n",
    "dummy = torch.randn(32, 1, image_size, image_size)\n",
    "out = model2(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba5ae3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6427ed2",
   "metadata": {},
   "source": [
    "Edit prior functions to switch on/off training and eval modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4ca7eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def compute_objective(net, X, y):\n",
    "    \"\"\" \n",
    "    Compute the multinomial logistic loss. \n",
    "    net is a module\n",
    "    X of shape (n, d) and y of shape (n,)\n",
    "    \"\"\"\n",
    "    # send \n",
    "    score = net(X)\n",
    "    # PyTorch's function cross_entropy computes the multinomial logistic loss\n",
    "    return cross_entropy(input=score, target=y, reduction='mean') \n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_accuracy(net, X, y):\n",
    "    \"\"\" \n",
    "    Compute the classification accuracy\n",
    "    based on majority vote from augmented images.\n",
    "    X of shape (n, d) and y of shape (n,)\n",
    "    \"\"\"\n",
    "    training_flag = net.training # Is model in training mode?\n",
    "    net.eval()\n",
    "    score = net(X)\n",
    "    predictions = torch.argmax(score, axis=1)  # class with highest score is predicted\n",
    "    \n",
    "    # Switch back to train when needed\n",
    "    if training_flag:\n",
    "        net.train()\n",
    "\n",
    "    return (predictions == y).sum() * 1.0 / y.shape[0]\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_logs(net, X_train, y_train, X_test, y_test, verbose=False):\n",
    "    \"\"\"\n",
    "    Compute loss & accuracy for train & test\n",
    "    Returns values in tuple in the order:\n",
    "    Train Loss, Train Accuracy, Test Loss, Test Accuracy\n",
    "    \"\"\"\n",
    "    training_flag = net.training\n",
    "    net.eval() # Switch to eval\n",
    "    train_loss = compute_objective(net, X_train, y_train)\n",
    "    test_loss = compute_objective(net, X_test, y_test)\n",
    "    \n",
    "    train_accuracy = compute_accuracy(net, X_train, y_train)\n",
    "    test_accuracy = compute_accuracy(net, X_test, y_test)\n",
    "    if verbose:\n",
    "        print(('Train Loss = {:.3f}, Train Accuracy = {:.3f}, ' + \n",
    "               'Test Loss = {:.3f}, Test Accuracy = {:.3f}').format(\n",
    "                train_loss.item(), train_accuracy.item(), \n",
    "                test_loss.item(), test_accuracy.item())\n",
    "    )\n",
    "    \n",
    "    # Switch back to training mode if needed\n",
    "    if training_flag:\n",
    "        net.train()\n",
    "\n",
    "    return (train_loss, train_accuracy, test_loss, test_accuracy)\n",
    "\n",
    "def minibatch_sgd_one_pass(net, X, y, learning_rate, batch_size, verbose=False):\n",
    "    \"\"\"\n",
    "    Performs one pass of stochastic gradient descent.\n",
    "    \"\"\"\n",
    "    num_examples = X.shape[0]\n",
    "    average_loss = 0.0\n",
    "    num_updates = int(round(num_examples / batch_size))\n",
    "    for i in range(num_updates):\n",
    "        idxs = np.random.choice(num_examples, size=(batch_size,))\n",
    "        X_transformed = X[idxs]\n",
    "        \n",
    "        # Be in training mode\n",
    "        net.train()\n",
    "        objective = compute_objective(net, X_transformed, y[idxs]) \n",
    "        average_loss = 0.99 * average_loss + 0.01 * objective.item()\n",
    "        \n",
    "        if verbose and (i+1) % 100 == 0:\n",
    "            print(average_loss)\n",
    "        \n",
    "        gradients = torch.autograd.grad(outputs=objective, inputs=net.parameters())\n",
    "        # perform SGD update inplace\n",
    "        with torch.no_grad():\n",
    "            for (w, g) in zip(net.parameters(), gradients):\n",
    "                w -= learning_rate * g\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bcf177",
   "metadata": {},
   "source": [
    "Compute local smoothness.  \n",
    "$$ \\hat{L}(w;u)=\\frac{||\\nabla f(w+u) - \\nabla f(w)||_2}{||u||_2}$$  \n",
    "where  \n",
    "$$ u = -\\eta \\frac{1}{B} \\sum_{b=1}^{B} \\nabla_w \\ell(y_{i_b},\\phi(x_{i_b};w))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fea0294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_local_smoothness(net, X, y, learning_rate, batch_size):\n",
    "    \"\"\"\n",
    "    Compute local smoothness\n",
    "    \"\"\"\n",
    "    net.train()\n",
    "    # Get batch\n",
    "    num_examples = X.shape[0]\n",
    "    idxs = np.random.choice(num_examples, size=(batch_size,))\n",
    "    \n",
    "    X_batch = X[idxs]\n",
    "    y_batch = y[idxs]\n",
    "    \n",
    "    # Compute u\n",
    "    obj = compute_objective(net, X_batch, y_batch)\n",
    "    grad_u = torch.autograd.grad(outputs=obj, inputs=net.parameters())\n",
    "    curr_u = [-learning_rate * g for g in grad_u]\n",
    "    \n",
    "    # Compute f(w)\n",
    "    obj = compute_objective(net, X, y)\n",
    "    grad_f_w = torch.autograd.grad(outputs=obj, inputs=net.parameters())\n",
    "    net_copy = copy.deepcopy(net)\n",
    "    \n",
    "    # Update copy inplace\n",
    "    with torch.no_grad():\n",
    "        for (w, u) in zip(net_copy.parameters(), curr_u):\n",
    "            w += u\n",
    "    \n",
    "    # Get grad_f_w_u\n",
    "    new_obj = compute_objective(net_copy, X, y)\n",
    "    grad_f_w_u = torch.autograd.grad(outputs=new_obj, inputs=net_copy.parameters())\n",
    "    \n",
    "    # Compute loss\n",
    "    numerator = 0\n",
    "    for (w_u, w) in zip(grad_f_w_u, grad_f_w):\n",
    "        numerator += torch.linalg.norm(w_u - w)\n",
    "    numerator = torch.sqrt(numerator)\n",
    "    denominator = 0\n",
    "    for u in curr_u:\n",
    "        denominator += torch.linalg.norm(u)\n",
    "    denominator = torch.sqrt(denominator)\n",
    "    \n",
    "    local_smoothness = numerator / denominator\n",
    "    print('Local smoothness: ', str(local_smoothness))\n",
    "    \n",
    "    return local_smoothness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d950c82c",
   "metadata": {},
   "source": [
    "Train basic `ConvNet` without `BatchNorm2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ebde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_net = ConvNet()\n",
    "\n",
    "# Parameters\n",
    "LEARNING_RATE = 0.04\n",
    "BATCH_SIZE = 32\n",
    "MAX_PASSES = 5\n",
    "\n",
    "logs = []\n",
    "for i in range(MAX_PASSES):\n",
    "    model = minibatch_sgd_one_pass(basic_net, X_train, y_train, LEARNING_RATE, BATCH_SIZE)\n",
    "    logs.append(\n",
    "        compute_logs(basic_net, X_train, y_train, X_test, y_test, verbose=True)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data598]",
   "language": "python",
   "name": "conda-env-data598-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
